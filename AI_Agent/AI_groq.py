import json
import time
import requests
import io
import re
import os
from typing import Dict, List, Any

try:
    import PyPDF2
except ImportError:
    print("Vui lÃ²ng cÃ i Ä‘áº·t PyPDF2: pip install PyPDF2")

# --- Cáº¤U HÃŒNH Há»† THá»NG THEO TÃ€I LIá»†U THIáº¾T Káº¾ ---
ESG_CONFIG = {
    "pillars": {
        "E": {"weight": 0.35, "name": "Environmental"},
        "S": {"weight": 0.35, "name": "Social"},
        "G": {"weight": 0.30, "name": "Governance"}
    },
    "metrics": {
        "E1": {"name": "PhÃ¡t tháº£i GHG", "pillar": "E", "weight": 0.40, "mandatory": True},
        "E2": {"name": "NÄƒng lÆ°á»£ng", "pillar": "E", "weight": 0.20, "mandatory": False},
        "E3": {"name": "Quáº£n lÃ½ NÆ°á»›c", "pillar": "E", "weight": 0.15, "mandatory": False},
        "E4": {"name": "Cháº¥t tháº£i", "pillar": "E", "weight": 0.15, "mandatory": False},
        "E5": {"name": "Chá»©ng chá»‰ Xanh", "pillar": "E", "weight": 0.10, "mandatory": False},
        "S1": {"name": "An toÃ n lao Ä‘á»™ng", "pillar": "S", "weight": 0.30, "mandatory": False},
        "S2": {"name": "Äa dáº¡ng giá»›i", "pillar": "S", "weight": 0.20, "mandatory": False},
        "S3": {"name": "ÄÃ o táº¡o", "pillar": "S", "weight": 0.20, "mandatory": False},
        "S4": {"name": "Chuá»—i cung á»©ng", "pillar": "S", "weight": 0.15, "mandatory": False},
        "S5": {"name": "Cá»™ng Ä‘á»“ng", "pillar": "S", "weight": 0.15, "mandatory": False},
        "G1": {"name": "Äá»™c láº­p HÄQT", "pillar": "G", "weight": 0.40, "mandatory": False},
        "G2": {"name": "Äáº¡o Ä‘á»©c kinh doanh", "pillar": "G", "weight": 0.30, "mandatory": True},
        "G3": {"name": "Minh báº¡ch thuáº¿", "pillar": "G", "weight": 0.15, "mandatory": False},
        "G4": {"name": "Báº£o máº­t dá»¯ liá»‡u", "pillar": "G", "weight": 0.15, "mandatory": False}
    }
}


class GreenScoreAgent:
    def __init__(self, api_key: str = ""):
        self.api_key = api_key
        # Groq API endpoint vÃ  models
        self.base_url = "https://api.groq.com/openai/v1"
        # Models hiá»‡n táº¡i cÃ²n hoáº¡t Ä‘á»™ng (thÃ¡ng 1/2025)
        self.models_to_try = [
            "llama-3.3-70b-versatile",  # Model chÃ­nh
            "llama-3.1-8b-instant",  # Nhanh, nháº¹
            "llama-3.2-90b-text-preview",  # Model lá»›n
            "gemma-7b-it"  # Dá»± phÃ²ng
        ]

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """Äá»c vÄƒn báº£n tá»« file PDF - Äá»ŒC Háº¾T Táº¤T Cáº¢ TRANG"""
        if not os.path.exists(pdf_path):
            print(f"âŒ KHÃ”NG TÃŒM THáº¤Y FILE Táº I: {pdf_path}")
            return ""

        print(f"ğŸ“„ AI Agent: Äang Ä‘á»c file PDF táº¡i: {pdf_path}...")
        text = ""
        try:
            with open(pdf_path, "rb") as f:
                reader = PyPDF2.PdfReader(f)
                total_pages = len(reader.pages)
                print(f"ğŸ“Š Tá»•ng sá»‘ trang: {total_pages}")

                # Äá»ŒC Háº¾T Táº¤T Cáº¢ TRANG
                for i in range(total_pages):
                    page_text = reader.pages[i].extract_text()
                    if page_text:
                        text += f"\n[TRANG {i + 1}]\n{page_text}"

                    # Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh
                    if (i + 1) % 10 == 0:
                        print(f"   â³ ÄÃ£ Ä‘á»c {i + 1}/{total_pages} trang...")

            print(f"âœ… ÄÃ£ Ä‘á»c thÃ nh cÃ´ng TOÃ€N Bá»˜ {total_pages} trang!")
            print(f"ğŸ“ Tá»•ng sá»‘ kÃ½ tá»±: {len(text):,}")
            return text
        except Exception as e:
            print(f"âŒ Lá»—i xá»­ lÃ½ PDF: {e}")
            return ""

    def collect_data_with_ai(self, report_content: str, is_mock: bool = False) -> str:
        """Gá»­i vÄƒn báº£n tá»›i Groq AI vÃ  nháº­n vá» JSON"""
        if is_mock or not self.api_key or len(self.api_key) < 10:
            return self._get_mock_schema("Lá»–I_FILE_HOáº¶C_KHOÃ_API")

        # GIáº¢M KÃCH THÆ¯á»šC Ä‘á»ƒ trÃ¡nh lá»—i 413
        # Groq free tier: ~12,000 tokens = ~30,000 kÃ½ tá»±
        max_content_length = 25000  # An toÃ n hÆ¡n

        if len(report_content) > max_content_length:
            print(f"âš ï¸ BÃ¡o cÃ¡o quÃ¡ dÃ i ({len(report_content):,} kÃ½ tá»±)")
            print(f"ğŸ“ Äang rÃºt gá»n xuá»‘ng {max_content_length:,} kÃ½ tá»±...")

            # Láº¥y Ä‘áº§u vÃ  cuá»‘i file (pháº§n quan trá»ng thÆ°á»ng á»Ÿ Ä‘Ã¢y)
            head_size = int(max_content_length * 0.7)
            tail_size = max_content_length - head_size

            report_content = (
                    report_content[:head_size] +
                    "\n\n[... PHáº¦N GIá»®A ÄÃƒ Bá»Š RÃšT Gá»ŒN ...]\n\n" +
                    report_content[-tail_size:]
            )

        metrics_desc = ", ".join([f"{k} ({v['name']})" for k, v in ESG_CONFIG['metrics'].items()])

        system_prompt = """Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch ESG chuyÃªn nghiá»‡p. 
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘á»c bÃ¡o cÃ¡o vÃ  Ä‘Ã¡nh giÃ¡ Ä‘iá»ƒm sá»‘ cho cÃ¡c chá»‰ sá»‘ ESG.
CHá»ˆ TRáº¢ Vá»€ JSON Há»¢P Lá»†, KHÃ”NG THÃŠM GÃŒ KHÃC."""

        user_prompt = f"""PhÃ¢n tÃ­ch bÃ¡o cÃ¡o ESG dÆ°á»›i Ä‘Ã¢y vÃ  tráº£ vá» JSON theo ÄÃšNG cáº¥u trÃºc:

{{
    "scores": {{
        "E1": <sá»‘ tá»« 0-100>,
        "E2": <sá»‘ tá»« 0-100>,
        "E3": <sá»‘ tá»« 0-100>,
        "E4": <sá»‘ tá»« 0-100>,
        "E5": <sá»‘ tá»« 0-100>,
        "S1": <sá»‘ tá»« 0-100>,
        "S2": <sá»‘ tá»« 0-100>,
        "S3": <sá»‘ tá»« 0-100>,
        "S4": <sá»‘ tá»« 0-100>,
        "S5": <sá»‘ tá»« 0-100>,
        "G1": <sá»‘ tá»« 0-100>,
        "G2": <sá»‘ tá»« 0-100>,
        "G3": <sá»‘ tá»« 0-100>,
        "G4": <sá»‘ tá»« 0-100>
    }},
    "insights": {{
        "E": "TÃ³m táº¯t vá» mÃ´i trÆ°á»ng",
        "S": "TÃ³m táº¯t vá» xÃ£ há»™i",
        "G": "TÃ³m táº¯t vá» quáº£n trá»‹"
    }},
    "flags": ["CÃ¡c cáº£nh bÃ¡o quan trá»ng náº¿u cÃ³"]
}}

Giáº£i thÃ­ch cÃ¡c chá»‰ sá»‘:
{metrics_desc}

Ná»˜I DUNG BÃO CÃO:
{report_content}

CHá»ˆ TRáº¢ Vá»€ JSON, KHÃ”NG GIáº¢I THÃCH THÃŠM."""

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        # Thá»­ láº§n lÆ°á»£t cÃ¡c model cho Ä‘áº¿n khi thÃ nh cÃ´ng
        for model in self.models_to_try:
            print(f"ğŸ§  AI Agent: Äang phÃ¢n tÃ­ch báº±ng Groq ({model})...")

            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 2000,  # Giáº£m xuá»‘ng Ä‘á»ƒ trÃ¡nh lá»—i
                "response_format": {"type": "json_object"}
            }

            try:
                url = f"{self.base_url}/chat/completions"
                response = requests.post(url, headers=headers, json=payload, timeout=90)

                if response.status_code == 200:
                    result = response.json()
                    raw_text = result['choices'][0]['message']['content']
                    # Loáº¡i bá» markdown code blocks náº¿u cÃ³
                    cleaned_text = re.sub(r'```json|```', '', raw_text).strip()
                    print(f"âœ… PhÃ¢n tÃ­ch thÃ nh cÃ´ng vá»›i {model}!")
                    return cleaned_text

                elif response.status_code == 400:
                    error_data = response.json()
                    if "decommissioned" in error_data.get("error", {}).get("message", ""):
                        print(f"âš ï¸ Model {model} Ä‘Ã£ ngá»«ng hoáº¡t Ä‘á»™ng, thá»­ model khÃ¡c...")
                        continue
                    else:
                        print(f"âŒ Lá»—i 400: {response.text[:200]}")
                        continue

                elif response.status_code == 404:
                    print(f"âš ï¸ Model {model} khÃ´ng kháº£ dá»¥ng, thá»­ model khÃ¡c...")
                    continue

                elif response.status_code == 413:
                    print(f"âš ï¸ Request quÃ¡ lá»›n cho {model}, thá»­ model khÃ¡c hoáº·c giáº£m kÃ­ch thÆ°á»›c...")
                    # Giáº£m thÃªm kÃ­ch thÆ°á»›c náº¿u váº«n quÃ¡ lá»›n
                    if len(report_content) > 15000:
                        report_content = report_content[:15000]
                    continue

                elif response.status_code == 429:
                    print(f"âš ï¸ Rate limit vá»›i {model}, thá»­ model khÃ¡c...")
                    continue

                else:
                    error_msg = response.text[:300]
                    print(f"âŒ Lá»—i API Groq (Code {response.status_code}): {error_msg}")
                    if "quota" in error_msg.lower() or "limit" in error_msg.lower():
                        continue  # Thá»­ model khÃ¡c náº¿u háº¿t quota

            except requests.exceptions.Timeout:
                print(f"â±ï¸ Timeout vá»›i {model}, thá»­ model khÃ¡c...")
                continue
            except Exception as e:
                print(f"âŒ Lá»—i vá»›i {model}: {str(e)[:100]}")
                continue

        # Náº¿u táº¥t cáº£ model Ä‘á»u tháº¥t báº¡i
        return self._get_mock_schema("Táº¤T_Cáº¢_MODEL_Äá»€U_THáº¤T_Báº I")

    def _get_mock_schema(self, reason: str) -> str:
        """Tráº£ vá» dá»¯ liá»‡u mÃ´ phá»ng khi cÃ³ lá»—i"""
        return json.dumps({
            "scores": {
                "E1": 85, "E2": 70, "E3": 0, "E4": 60, "E5": 40,
                "S1": 90, "S2": 50, "S3": 80, "S4": 0, "S5": 60,
                "G1": 100, "G2": 100, "G3": 90, "G4": 85
            },
            "insights": {
                "E": f"âš ï¸ Dá»¯ liá»‡u mÃ´ phá»ng. LÃ½ do: {reason}",
                "S": "Vui lÃ²ng kiá»ƒm tra API Key táº¡i console.groq.com",
                "G": "Groq API hoÃ n toÃ n miá»…n phÃ­, khÃ´ng cáº§n tháº» tÃ­n dá»¥ng!"
            },
            "flags": [f"âš ï¸ CHáº¾ Äá»˜ MÃ” PHá»NG - {reason}"]
        })

    def process_final_report(self, ai_output_json: str) -> Dict[str, Any]:
        """Xá»­ lÃ½ káº¿t quáº£ tá»« AI vÃ  tÃ­nh toÃ¡n Ä‘iá»ƒm sá»‘ cuá»‘i cÃ¹ng"""
        try:
            data = json.loads(ai_output_json)
        except Exception as e:
            print(f"âš ï¸ Lá»—i parse JSON: {e}")
            data = json.loads(self._get_mock_schema("Lá»–I_PHÃ‚N_TÃCH_JSON"))

        raw_scores = data.get("scores", {})
        pillar_results = {}
        final_flags = data.get("flags", [])
        is_gold_locked = False

        # TÃ­nh Ä‘iá»ƒm cho tá»«ng trá»¥ cá»™t (E, S, G)
        for p_code, p_info in ESG_CONFIG['pillars'].items():
            p_metrics = {k: v for k, v in ESG_CONFIG['metrics'].items() if v['pillar'] == p_code}
            weighted_sum = 0.0
            available_weight = 0.0

            for m_code, m_info in p_metrics.items():
                val = raw_scores.get(m_code, 0)
                if val > 0:
                    weighted_sum += (val * m_info['weight'])
                    available_weight += m_info['weight']
                elif m_info['mandatory']:
                    is_gold_locked = True
                    msg = f"âš ï¸ THIáº¾U CHá»ˆ Sá» Báº®T BUá»˜C: {m_info['name']}"
                    if msg not in final_flags:
                        final_flags.append(msg)

            p_score = (weighted_sum / available_weight) if available_weight > 0 else 0

            # Giáº£m Ä‘iá»ƒm náº¿u thiáº¿u chá»‰ sá»‘ báº¯t buá»™c
            if any(m['mandatory'] and raw_scores.get(k, 0) == 0 for k, m in p_metrics.items()):
                p_score *= 0.5

            pillar_results[p_code] = round(p_score, 2)

        # TÃ­nh tá»•ng Ä‘iá»ƒm
        total_score = round(sum(
            pillar_results[p] * ESG_CONFIG['pillars'][p]['weight']
            for p in pillar_results
        ), 2)

        # Xáº¿p háº¡ng
        rank = "UNRANKED"
        if total_score >= 80 and not is_gold_locked:
            rank = "GOLD"
        elif total_score >= 55:
            rank = "SILVER"
        elif total_score >= 35:
            rank = "BRONZE"

        return {
            "metadata": {
                "agent": "GreenScore AI Agent (Groq)",
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "api": "Groq (FREE)"
            },
            "evaluation": {
                "score": total_score,
                "rank": rank,
                "badge": f"GREENSCORE_{rank}_NFT",
                "pillar_breakdown": pillar_results
            },
            "analysis": {
                "insights": data.get("insights", {}),
                "flags": list(set(final_flags)),
                "raw_scores": raw_scores
            }
        }


if __name__ == "__main__":
    print("ğŸŒ± GREEN SCORE AI AGENT - Groq Edition (FREE & FAST)")
    print("=" * 60)

    # 1. API KEY tá»« Groq (https://console.groq.com/keys)
    MY_API_KEY = "YOUR_GROQ_API_KEY_HERE"  # Thay báº±ng API key cá»§a báº¡n

    # 2. FILE PDF
    PDF_FILE = r"D:/OneDrive - uel.edu.vn/HocTap_UEL/Cuoc_thi_hoc_thuat/ESG/ESG-GreenScore-for-Business/baocaovnm.pdf"

    # Kiá»ƒm tra API key
    if MY_API_KEY == "YOUR_GROQ_API_KEY_HERE":
        print("âš ï¸ Cáº¢NH BÃO: Báº¡n chÆ°a thay API key!")
        print("ğŸ“ HÆ°á»›ng dáº«n:")
        print("   1. Truy cáº­p: https://console.groq.com/keys")
        print("   2. ÄÄƒng kÃ½/ÄÄƒng nháº­p (MIá»„N PHÃ)")
        print("   3. Táº¡o API key má»›i")
        print("   4. Copy vÃ  dÃ¡n vÃ o biáº¿n MY_API_KEY trong code")
        print("\nğŸ”„ Äang cháº¡y á»Ÿ CHáº¾ Äá»˜ MÃ” PHá»NG...\n")

    agent = GreenScoreAgent(api_key=MY_API_KEY)
    content = agent.extract_text_from_pdf(PDF_FILE)

    is_using_mock = not bool(content)
    json_from_ai = agent.collect_data_with_ai(content, is_mock=is_using_mock)
    final_report = agent.process_final_report(json_from_ai)

    print("\n" + "â•" * 60)
    print("ğŸ¯ Káº¾T QUáº¢ ÄÃNH GIÃ Tá»° Äá»˜NG (GREEN SCORE)")
    print("â•" * 60)
    print(json.dumps(final_report, indent=4, ensure_ascii=False))
    print("â•" * 60)

    if "CHáº¾ Äá»˜ MÃ” PHá»NG" in str(final_report):
        print("\nâš ï¸ Káº¿t quáº£ trÃªn lÃ  dá»¯ liá»‡u mÃ´ phá»ng!")
        print("ğŸ’¡ Äá»ƒ cÃ³ káº¿t quáº£ tháº­t, vui lÃ²ng:")
        print("   - Kiá»ƒm tra API key Groq")
        print("   - Äáº£m báº£o file PDF tá»“n táº¡i")